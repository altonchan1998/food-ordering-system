server:
  port: 8181

logging:
  level:
    com.food.ordering.system: DEBUG

order-service:
  payment-request-topic-name: payment-request
  payment-response-topic-name: payment-response
  restaurant-approval-request-topic-name: restaurant-approval-request
  restaurant-approval-response-topic-name: restaurant-approval-response
  outbox-scheduler-fixed-rate: 10000
  outbox-scheduler-initial-delay: 10000

spring:
  jpa:
    open-in-view: false
    show-sql: true
    database-platform: org.hibernate.dialect.PostgreSQL9Dialect
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQL9Dialect
  datasource:
    url: jdbc:postgresql://localhost:5432/postgres?currentSchema=order&binaryTransfer=true&reWriteBatchedInserts=true&stringtype=unspecified
    username: postgres
    password: admin
    driver-class-name: org.postgresql.Driver
    platform: postgres
    schema: classpath:init-schema.sql
    initialization-mode: always

kafka-config:
  bootstrap-servers: localhost:19092, localhost:29092, localhost:39092
  schema-registry-url-key: schema.registry.url
  schema-registry-url: http://localhost:8081
  num-of-partitions: 3
  replication-factor: 3

kafka-producer-config:
  key-serializer-class: org.apache.kafka.common.serialization.StringSerializer
  value-serializer-class: io.confluent.kafka.serializers.KafkaAvroSerializer
  compression-type: snappy
  acks: all
  batch-size: 16384
  batch-size-boost-factor: 100
  linger-ms: 5
  request-timeout-ms: 60000
  retry-count: 5

kafka-consumer-config:
  key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
  value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
  payment-consumer-group-id: payment-topic-consumer
  restaurant-approval-consumer-group-id: restaurant-approval-topic-consumer
  auto-offset-reset: earliest # If no offset available, start consumer topic message from the beginning of partition
  specific-avro-reader-key: specific.avro.reader
  specific-avro-reader: true
  batch-listener: true # Consume messages by batch instead of one by one
  auto-startup: true # kafka listener start up automatically
  concurrency-level: 3 # 3 threads in this application instance for consuming Kafka messages, max = no. of partition / no. of application instance
  session-timeout-ms: 10000 # if broker cannot get a signal from consumer in ? ms, broker will mark the consumer as dead
  heartbeat-interval-ms: 3000 # Frequency of sending heartbeat from the consumer to brokers
  max-poll-interval-ms: 300000 # if consumers not polling in ?ms, broker will assign the partitions to other available consumers
  max-poll-records: 500 # max no. of records can be fetched in each call
  max-partition-fetch-bytes-default: 1048576 # max bytes of records can be fetched in each call
  max-partition-fetch-bytes-boost-factor: 1
  poll-timeout-ms: 150 # if consumer try to fetch data from Kafka and no data presents, it will block the client code to and wait ?s and fetch data again. (block thread for waiting vs cpi burning for while loop)
